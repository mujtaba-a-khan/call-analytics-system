# ğŸ“ Call Analytics System

A professional, locally-hosted call analytics system with speech-to-text, semantic search, and natural language Q&A capabilities. Built with Python 3.13, Streamlit, and ChromaDB.

[![Python 3.13](https://img.shields.io/badge/Python-3.13-informational?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-app-informational?logo=streamlit)](https://streamlit.io/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-vectorDB-informational)](https://www.trychroma.com/)
[![Whisper](https://img.shields.io/badge/Whisper-STT-informational?logo=openai)](https://github.com/openai/whisper)
[![License: MIT](https://img.shields.io/badge/License-MIT-success)](LICENSE)

## Table of Contents

<details>
  <summary><strong>âœ¨ Features</strong></summary>

<a id="features"></a>

- **ğŸµ Audio Processing**: Automatic transcription of call recordings using Whisper STT  
- **ğŸ“„ CSV Import**: Bulk import of existing call transcripts  
- **ğŸ·ï¸ Intelligent Labeling**: Automatic categorization of calls by type and outcome  
- **ğŸ” Semantic Search**: Vector-based search using ChromaDB and sentence transformers  
- **â“ Natural Language Q&A**: Query your data using plain English  
- **ğŸ“Š Rich Analytics**: Interactive dashboards with metrics and visualizations  
- **ğŸ”’ Privacy-First**: All processing happens locallyâ€”no data leaves your machine  
- **âš¡ High Performance**: Efficient caching and batch processing capabilities  

[â†‘ Back to top](#readme)
</details>

<details>
  <summary><strong>ğŸš€ Quick Start</strong></summary>

<a id="quick-start"></a>

### Prerequisites
- Python 3.13 or higher  
- FFmpeg (for audio processing)  
- 8GB+ RAM recommended  
- CUDA-capable GPU (optional, for faster processing)

### Installation
1. **Clone the repository**
   ```bash
   git clone https://github.com/mujtaba-a-khan/call-analytics-system.git
   cd call-analytics-system
   ```
2. **Install FFmpeg**
   ```bash
   # macOS
   brew install ffmpeg

   # Ubuntu/Debian
   sudo apt-get install ffmpeg

   # Windows: download from https://ffmpeg.org/download.html
   ```
3. **Create virtual environment**
   ```bash
   python3.13 -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```
4. **Install dependencies**
   ```bash
   pip install -e .
   # For development
   pip install -e ".[dev]"
   # For documentation
   pip install -e ".[docs]"
   ```
5. **Run Scripts to Setup Enviroment**
   ```bash
   python scripts/setup_enviroment.py

   python scripts/download_models.py
   ```
6. **Run the application**
   ```bash
   streamlit run src/ui/app.py
   ```
App opens at `http://localhost:8501`.

[â†‘ Back to top](#readme)
</details>

<details>
  <summary><strong>ğŸ“ Project Structure</strong></summary>

<a id="project-structure"></a>

```text
call-analytics-system/
â”‚
â”œâ”€â”€ pyproject.toml                 # Project configuration and dependencies
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ .gitignore                     # Git ignore file
â”œâ”€â”€ requirements.txt               # Alternative dependency list
â”‚
â”œâ”€â”€ config/                        # Configuration files
â”‚   â”œâ”€â”€ app.toml                   # Main application settings
â”‚   â”œâ”€â”€ models.toml                # LLM and STT model configurations
â”‚   â”œâ”€â”€ vectorstore.toml           # Vector database settings
â”‚   â””â”€â”€ rules.toml                 # Call labeling rules
â”‚
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audio_processor.py     # Audio file processing
â”‚   â”‚   â”œâ”€â”€ csv_processor.py       # CSV file processing
â”‚   â”‚   â”œâ”€â”€ data_schema.py         # Data models and schemas
â”‚   â”‚   â”œâ”€â”€ labeling_engine.py     # Call labeling logic
â”‚   â”‚   â””â”€â”€ storage_manager.py     # Data persistence
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ filters.py             # Data filtering logic
â”‚   â”‚   â”œâ”€â”€ aggregations.py        # KPIs and metrics
â”‚   â”‚   â”œâ”€â”€ semantic_search.py     # Semantic search implementation
â”‚   â”‚   â””â”€â”€ query_interpreter.py   # Natural language query processing
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ whisper_stt.py         # Speech-to-text engine
â”‚   â”‚   â”œâ”€â”€ llm_interface.py       # Local LLM integration
â”‚   â”‚   â””â”€â”€ embeddings.py          # Text embedding generation
â”‚   â”œâ”€â”€ vectordb/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chroma_client.py       # ChromaDB interface
â”‚   â”‚   â”œâ”€â”€ indexer.py             # Document indexing
â”‚   â”‚   â””â”€â”€ retriever.py           # Document retrieval
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                 # Main Streamlit application
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.py       # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py          # File upload interface
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py        # Analysis view
â”‚   â”‚   â”‚   â””â”€â”€ qa_interface.py    # Q&A interface
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ charts.py          # Chart components
â”‚   â”‚       â”œâ”€â”€ filters.py         # Filter components
â”‚   â”‚       â”œâ”€â”€ tables.py          # Table components
â”‚   â”‚       â””â”€â”€ metrics.py         # Metric display components
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ text_processing.py     # Text utilities
â”‚       â”œâ”€â”€ file_handlers.py       # File I/O utilities
â”‚       â”œâ”€â”€ formatters.py          # Formatting Utilities
â”‚       â”œâ”€â”€ validators.py          # Data validation
â”‚       â””â”€â”€ logger.py              # Logging configuration
â”‚
â”œâ”€â”€ data/                          # Data directory
â”‚   â”œâ”€â”€ uploads/                   # User uploaded files
â”‚   â”œâ”€â”€ processed/                 # Processed data
â”‚   â”œâ”€â”€ cache/                     # Cache directory
â”‚   â””â”€â”€ vectorstore/               # Vector database storage
â”œâ”€â”€ models/                        # Model storage
â”‚   â””â”€â”€ whisper/                   # Whisper models
â”œâ”€â”€ tests/                         # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_core/
â”‚   â”œâ”€â”€ test_analysis/
â”‚   â””â”€â”€ test_ml/
â””â”€â”€ scripts/
    â”œâ”€â”€ setup_environment.py
    â”œâ”€â”€ download_models.py
    â””â”€â”€ rebuild_index.py
```

[â†‘ Back to top](#readme)
</details>

<details>
  <summary><strong>ğŸ”§ Configuration</strong></summary>

<a id="configuration"></a>

### Audio Settings (`config/app.toml`)
```toml
[audio]
supported_formats = ["wav", "mp3", "m4a", "flac"]
max_duration_minutes = 60
sample_rate = 16000
channels = 1
```

### Model Settings (`config/models.toml`)
```toml
[whisper]
model_size = "small.en"  # tiny, base, small, medium, large
compute_type = "int8"    # int8, float16, float32
device = "auto"          # auto, cpu, cuda
```

### Vector Store (`config/vectorstore.toml`)
```toml
[vectorstore]
provider = "chromadb"
collection_name = "call_transcripts"
distance_metric = "cosine"

[embeddings]
provider = "sentence-transformers"
model_name = "all-MiniLM-L6-v2"
```

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ“Š Usage Guide</strong></summary>

<a id="usage-guide"></a>

### 1) Upload Files
- **Audio**: WAV, MP3, M4A, FLAC  
- **CSV**: transcripts with metadata

Required columns: `call_id`, `start_time`, `duration_seconds`, `transcript`  
Optional: `agent_id`, `campaign`, `customer_name`, `product_name`, `amount`

### 2) Apply Filters
By date, type (Inquiry/Support/Billing/Complaint), outcome, agent, campaign.

### 3) View Analytics
KPIs, distributions, agent performance, peak hours.

### 4) Natural Language Q&A
Examples:
- â€œWhat were the main complaints last week?â€
- â€œShow refund requests from agent Johnâ€
- â€œCalls about billing issues over 5 minutesâ€

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ”¬ Advanced Features</strong></summary>

<a id="advanced-features"></a>

**Semantic Search**
```python
results = vector_db.search(
    query_text="customer asking for refund",
    top_k=10,
    filter_dict={"agent_id": "john_doe"}
)
```

**Custom Labeling Rules** (`config/rules.toml`)
```toml
[rules.call_types]
inquiry = ["information", "question", "how to"]
support = ["not working", "error", "problem", "issue"]
billing = ["invoice", "payment", "charge", "bill"]
complaint = ["unhappy", "disappointed", "poor service"]
```

**Batch Processing**
```bash
python scripts/rebuild_index.py --batch-size 50
```

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ› ï¸ Development</strong></summary>

<a id="development"></a>

```bash
pytest tests/ -v --cov=src      # tests
black src/ tests/               # formatting
ruff check src/ tests/          # lint
mypy src/                       # types
# docs
cd docs && make html
```

[â†‘ Back to top](#readme)
</details>

<details>
  <summary><strong>ğŸ“ˆ Performance Tips</strong></summary>

<a id="performance-tips"></a>

1. Use CUDA/GPU for Whisper  
2. Enable caching in `config/app.toml`  
3. Batch processing for large imports  
4. Rebuild vector index periodically  

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ”’ Security & Privacy</strong></summary>

<a id="security--privacy"></a>

- Local processing only  
- No external APIs by default  
- Optional PII masking  
- Local storage with optional encryption  

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ› Troubleshooting</strong></summary>

<a id="troubleshooting"></a>

**FFmpeg not found**
```bash
ffmpeg -version
# Add to PATH if needed:
export PATH=$PATH:/path/to/ffmpeg
```

**Out of memory**  
Reduce batch size; process smaller groups; increase swap.

**Slow transcription**  
Use smaller Whisper model; enable GPU; reduce audio quality.

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ“ License</strong></summary>

<a id="license"></a>

MIT License â€” see [LICENSE](LICENSE).

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ¤ Contributing</strong></summary>

<a id="contributing"></a>

Contributions welcome! Please read `CONTRIBUTING.md`.

[â†‘ Back to top](#readme)
</details>

<details>
  <summary><strong>ğŸ“§ Support</strong></summary>

<a id="support"></a>

- Open an issue on GitHub  
- Check `/docs`  
- Review closed issues

[â†‘ Back to top](#readme)
</details>


<details>
  <summary><strong>ğŸ™ Acknowledgments</strong></summary>

<a id="acknowledgments"></a>

- OpenAI Whisper for speech-to-text  
- ChromaDB for vector storage  
- Streamlit for the UI  
- The open-source community

[â†‘ Back to top](#readme)
</details>
