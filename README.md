# ğŸ“ Call Analytics System

A professional, locally-hosted call analytics system with speech-to-text, semantic search, and natural language Q&A capabilities. Built with Python 3.13, Streamlit, and ChromaDB.

## âœ¨ Features

- **ğŸµ Audio Processing**: Automatic transcription of call recordings using Whisper STT
- **ğŸ“„ CSV Import**: Bulk import of existing call transcripts
- **ğŸ·ï¸ Intelligent Labeling**: Automatic categorization of calls by type and outcome
- **ğŸ” Semantic Search**: Vector-based search using ChromaDB and sentence transformers
- **â“ Natural Language Q&A**: Query your data using plain English
- **ğŸ“Š Rich Analytics**: Interactive dashboards with metrics and visualizations
- **ğŸ”’ Privacy-First**: All processing happens locally - no data leaves your machine
- **âš¡ High Performance**: Efficient caching and batch processing capabilities

## ğŸš€ Quick Start

### Prerequisites

- Python 3.13 or higher
- FFmpeg (for audio processing)
- 8GB+ RAM recommended
- CUDA-capable GPU (optional, for faster processing)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/call-analytics-system.git
cd call-analytics-system
```

2. **Install FFmpeg**
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

3. **Create virtual environment**
```bash
python3.13 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

4. **Install dependencies**
```bash
pip install -e .

# For development
pip install -e ".[dev]"

# For documentation
pip install -e ".[docs]"
```

5. **Download Whisper model**
```bash
python scripts/download_models.py
```

6. **Run the application**
```bash
streamlit run src/ui/app.py
```

The application will open in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
call-analytics-system/
â”‚
â”œâ”€â”€ pyproject.toml                 # Project configuration and dependencies
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ .gitignore                      # Git ignore file
â”œâ”€â”€ requirements.txt                # Alternative dependency list
â”‚
â”œâ”€â”€ config/                         # Configuration files
â”‚   â”œâ”€â”€ app.toml                   # Main application settings
â”‚   â”œâ”€â”€ models.toml                # LLM and STT model configurations
â”‚   â”œâ”€â”€ vectorstore.toml           # Vector database settings
â”‚   â””â”€â”€ rules.toml                 # Call labeling rules
â”‚
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                      # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audio_processor.py    # Audio file processing
â”‚   â”‚   â”œâ”€â”€ csv_processor.py      # CSV file processing
â”‚   â”‚   â”œâ”€â”€ data_schema.py        # Data models and schemas
â”‚   â”‚   â”œâ”€â”€ labeling_engine.py    # Call labeling logic
â”‚   â”‚   â””â”€â”€ storage_manager.py    # Data persistence
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                  # Analysis modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ filters.py            # Data filtering logic
â”‚   â”‚   â”œâ”€â”€ aggregations.py       # KPIs and metrics
â”‚   â”‚   â”œâ”€â”€ semantic_search.py    # Semantic search implementation
â”‚   â”‚   â””â”€â”€ query_interpreter.py  # Natural language query processing
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/                        # Machine learning components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ whisper_stt.py        # Speech-to-text engine
â”‚   â”‚   â”œâ”€â”€ llm_interface.py      # Local LLM integration
â”‚   â”‚   â””â”€â”€ embeddings.py         # Text embedding generation
â”‚   â”‚
â”‚   â”œâ”€â”€ vectordb/                  # Vector database
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chroma_client.py      # ChromaDB interface
â”‚   â”‚   â”œâ”€â”€ indexer.py            # Document indexing
â”‚   â”‚   â””â”€â”€ retriever.py          # Document retrieval
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                        # User interface
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ app.py                # Main Streamlit application
â”‚   â”‚   â”œâ”€â”€ pages/                # Streamlit pages
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.py      # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py         # File upload interface
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py       # Analysis view
â”‚   â”‚   â”‚   â””â”€â”€ qa_interface.py   # Q&A interface
â”‚   â”‚   â””â”€â”€ components/            # Reusable UI components
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ charts.py         # Chart components
â”‚   â”‚       â”œâ”€â”€ filters.py        # Filter components
â”‚   â”‚       â”œâ”€â”€ tables.py         # Table components
â”‚   â”‚       â””â”€â”€ metrics.py        # Metric display components
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ text_processing.py    # Text utilities
â”‚       â”œâ”€â”€ file_handlers.py      # File I/O utilities
â”‚       â”œâ”€â”€ validators.py         # Data validation
â”‚       â””â”€â”€ logger.py             # Logging configuration
â”‚
â”œâ”€â”€ data/                          # Data directory
â”‚   â”œâ”€â”€ uploads/                   # User uploaded files
â”‚   â”œâ”€â”€ processed/                 # Processed data
â”‚   â”œâ”€â”€ cache/                     # Cache directory
â”‚   â””â”€â”€ vectorstore/               # Vector database storage
â”‚
â”œâ”€â”€ models/                        # Model storage
â”‚   â””â”€â”€ whisper/                   # Whisper models
â”‚
â”œâ”€â”€ tests/                         # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_core/                # Core module tests
â”‚   â”œâ”€â”€ test_analysis/            # Analysis module tests
â”‚   â””â”€â”€ test_ml/                  # ML module tests
â”‚
â””â”€â”€ scripts/                       # Utility scripts
    â”œâ”€â”€ setup_environment.py       # Environment setup
    â”œâ”€â”€ download_models.py         # Model download script
    â””â”€â”€ rebuild_index.py          # Vector index rebuilding
```

## ğŸ”§ Configuration

### Audio Settings (config/app.toml)
```toml
[audio]
supported_formats = ["wav", "mp3", "m4a", "flac"]
max_duration_minutes = 60
sample_rate = 16000
channels = 1
```

### Model Settings (config/models.toml)
```toml
[whisper]
model_size = "small.en"  # Options: tiny, base, small, medium, large
compute_type = "int8"    # Options: int8, float16, float32
device = "auto"          # Options: auto, cpu, cuda
```

### Vector Store Settings (config/vectorstore.toml)
```toml
[vectorstore]
provider = "chromadb"
collection_name = "call_transcripts"
distance_metric = "cosine"

[embeddings]
provider = "sentence-transformers"
model_name = "all-MiniLM-L6-v2"
```

## ğŸ“Š Usage Guide

### 1. Upload Files

- **Audio Files**: Upload WAV, MP3, M4A, or FLAC files
- **CSV Files**: Import existing transcripts with metadata

Required CSV columns:
- `call_id`: Unique identifier
- `start_time`: Timestamp (ISO format)
- `duration_seconds`: Call duration
- `transcript`: Call transcript text

Optional columns:
- `agent_id`, `campaign`, `customer_name`, `product_name`, `amount`

### 2. Apply Filters

Use the sidebar to filter calls by:
- Date range
- Call type (Inquiry, Support, Billing/Sales, Complaint)
- Outcome (Resolved, Callback, Refund, Sale-close)
- Agent
- Campaign

### 3. View Analytics

The dashboard provides:
- Key metrics (total calls, connection rate, average duration)
- Distribution charts (types, outcomes, timeline)
- Agent performance metrics
- Peak hours and busy days analysis

### 4. Natural Language Q&A

Ask questions like:
- "What were the main complaints last week?"
- "Show me all refund requests from agent John"
- "Find calls about billing issues that lasted over 5 minutes"

## ğŸ”¬ Advanced Features

### Semantic Search

The system uses ChromaDB with sentence transformers to enable semantic search:

```python
# Example: Find similar calls
results = vector_db.search(
    query_text="customer asking for refund",
    top_k=10,
    filter_dict={"agent_id": "john_doe"}
)
```

### Custom Labeling Rules

Edit `config/rules.toml` to customize call categorization:

```toml
[rules.call_types]
inquiry = ["information", "question", "how to"]
support = ["not working", "error", "problem", "issue"]
billing = ["invoice", "payment", "charge", "bill"]
complaint = ["unhappy", "disappointed", "poor service"]
```

### Batch Processing

Process multiple files efficiently:

```bash
python scripts/rebuild_index.py --batch-size 50
```

## ğŸ› ï¸ Development

### Running Tests
```bash
pytest tests/ -v --cov=src
```

### Code Formatting
```bash
black src/ tests/
ruff check src/ tests/
```

### Type Checking
```bash
mypy src/
```

### Building Documentation
```bash
cd docs/
make html
```

## ğŸ“ˆ Performance Tips

1. **GPU Acceleration**: Install CUDA for faster Whisper processing
2. **Caching**: Enable caching in `config/app.toml` for repeated queries
3. **Batch Processing**: Process files in batches for better efficiency
4. **Index Optimization**: Rebuild vector index periodically

## ğŸ”’ Security & Privacy

- **Local Processing**: All data processing happens on your machine
- **No External APIs**: No data is sent to external services
- **Configurable PII Masking**: Optional customer name masking
- **Secure Storage**: Data stored locally with configurable encryption

## ğŸ› Troubleshooting

### Common Issues

**FFmpeg not found**
```bash
# Verify installation
ffmpeg -version

# Add to PATH if needed
export PATH=$PATH:/path/to/ffmpeg
```

**Out of memory errors**
- Reduce batch size in configuration
- Process files in smaller groups
- Increase system swap space

**Slow transcription**
- Use smaller Whisper model (tiny or base)
- Enable GPU acceleration
- Reduce audio quality settings

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions are welcome! Please read CONTRIBUTING.md for guidelines.

## ğŸ“§ Support

For issues and questions:
- Open an issue on GitHub
- Check the documentation at `/docs`
- Review closed issues for solutions

## ğŸ™ Acknowledgments

- OpenAI Whisper for speech-to-text
- ChromaDB for vector storage
- Streamlit for the UI framework
- The open-source community

---

Built with â¤ï¸ for efficient call analytics